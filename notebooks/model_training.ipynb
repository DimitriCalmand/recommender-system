{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:50:47.432466Z",
     "start_time": "2025-05-14T14:50:45.668983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.evaluation import precision_at_k, ndcg_at_k, mean_average_precision_at_k\n",
    "from src.utils.utils import safe_parse_feat\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "id": "7be6823d77d8a33a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jules_/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the Data",
   "id": "f3d4d8bd2ed08e1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:51:02.106505Z",
     "start_time": "2025-05-14T14:50:47.436233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the path to the processed data\n",
    "processed_path = \"../data/processed/\"\n",
    "\n",
    "# Load the processed datasets\n",
    "interactions_train = pd.read_csv(os.path.join(processed_path, \"interactions_train.csv\"))\n",
    "interactions_test = pd.read_csv(os.path.join(processed_path, \"interactions_test.csv\"))\n",
    "user_features = pd.read_csv(os.path.join(processed_path, \"user_features_engineered.csv\"))\n",
    "video_metadata = pd.read_csv(os.path.join(processed_path, \"video_metadata.csv\"))\n",
    "\n",
    "video_metadata[\"feat\"] = video_metadata[\"feat\"].apply(safe_parse_feat)\n",
    "video_metadata = video_metadata[video_metadata[\"feat\"].notnull()]\n",
    "\n",
    "user_features[\"preferred_category\"] = user_features[\"preferred_category\"].apply(safe_parse_feat)\n",
    "user_features = user_features[user_features[\"preferred_category\"].notnull()]\n",
    "\n",
    "user_features[\"friends_preferred_category\"] = user_features[\"friends_preferred_category\"].apply(safe_parse_feat)\n",
    "user_features = user_features[user_features[\"friends_preferred_category\"].notnull()]\n",
    "\n",
    "#Print the maximum value for each onehot\n",
    "for i in range(1, 18):\n",
    "    user_features[f\"onehot_feat{i}\"] = user_features[f\"onehot_feat{i}\"].fillna(0)\n",
    "    user_features[f\"onehot_feat{i}\"] = user_features[f\"onehot_feat{i}\"].apply(lambda x: x if x >= 0 else 0)\n",
    "    if user_features[f\"onehot_feat{i}\"].dtype == float:\n",
    "        user_features = user_features.astype({f\"onehot_feat{i}\": int})\n",
    "\n",
    "video_metadata[\"video_tag_id\"] = video_metadata[\"video_tag_id\"].fillna(0)\n",
    "video_metadata[\"video_tag_id\"] = video_metadata[\"video_tag_id\"].apply(lambda x: x if x >= 0 else 0)\n",
    "if video_metadata[\"video_tag_id\"].dtype == float:\n",
    "    video_metadata = video_metadata.astype({\"video_tag_id\": int})"
   ],
   "id": "40244dfd9ccd2683",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collaborative Filtering with ALS",
   "id": "ad7a5b654ae7a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:39.809460Z",
     "start_time": "2025-05-14T14:51:02.199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the interaction matrix\n",
    "interaction_matrix = csr_matrix((interactions_train['watch_ratio'],\n",
    "                                 (interactions_train['user_id'], interactions_train['video_id'])))\n",
    "\n",
    "# Create the test interaction matrix\n",
    "test_interaction_matrix = csr_matrix((interactions_test['watch_ratio'],\n",
    "                                      (interactions_test['user_id'], interactions_test['video_id'])))\n",
    "\n",
    "# Initialize the ALS model\n",
    "als_model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
    "\n",
    "# Train the ALS model\n",
    "als_model.fit(interaction_matrix)"
   ],
   "id": "ed9a49d7ba1fbe69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jules_/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 20/20 [01:36<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate the ALS Model",
   "id": "c655e6c961b40176"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:41.204360Z",
     "start_time": "2025-05-14T14:52:39.842772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Precision@K and Recall@K\n",
    "K = 30\n",
    "ndcg = ndcg_at_k(als_model, interaction_matrix, test_interaction_matrix, K=K, show_progress=True, num_threads=1)\n",
    "ma_precision = mean_average_precision_at_k(als_model, interaction_matrix, test_interaction_matrix, K=K, show_progress=True, num_threads=1)\n",
    "precision = precision_at_k(als_model, interaction_matrix, test_interaction_matrix, K=K, show_progress=True, num_threads=1)\n",
    "\n",
    "print(f\"NDCG@{K}: {ndcg} - Best for position-aware ranking quality.\")\n",
    "print(f\"MAP@{K}: {ma_precision} – Great global ranking evaluation.\")\n",
    "print(f\"Precision@{K}: {precision} - Simple and intuitive.\")"
   ],
   "id": "ff8329dff163fce1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7176/7176 [00:00<00:00, 14948.91it/s]\n",
      "100%|██████████| 7176/7176 [00:00<00:00, 16402.59it/s]\n",
      "100%|██████████| 7176/7176 [00:00<00:00, 16457.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@30: 0.8052790170186468 - Best for position-aware ranking quality.\n",
      "MAP@30: 0.6876894387588626 – Great global ranking evaluation.\n",
      "Precision@30: 0.7892445844308484 - Simple and intuitive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute recommendations for ALS",
   "id": "ed58fcba1405f8df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:42.096163Z",
     "start_time": "2025-05-14T14:52:41.221422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend_top_n_als(model, user_ids, video_ids, top_n=5):\n",
    "    recommendations_als = {}\n",
    "    for user_id in user_ids:\n",
    "        # Get the user's recommendations from the ALS model\n",
    "        if 0 <= user_id < interaction_matrix.shape[0]:\n",
    "            user_recs = model.recommend(user_id, interaction_matrix[user_id], N=top_n, filter_already_liked_items=True)\n",
    "            # Extract the video IDs from the recommendations\n",
    "            rec_video_ids = [rec[0] for rec in user_recs]\n",
    "            recommendations_als[user_id] = rec_video_ids\n",
    "    return recommendations_als\n",
    "\n",
    "train_video_ids = set(interactions_train['video_id'].unique())\n",
    "valid_video_ids = [vid for vid in video_metadata['video_id'].unique() if vid in train_video_ids]\n",
    "\n",
    "user_ids = user_features['user_id'].values\n",
    "\n",
    "als_recommendations = recommend_top_n_als(als_model, user_ids, valid_video_ids, top_n=30)"
   ],
   "id": "9f05b87dbf94b662",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Content-Based Filtering with and Cosine Similarity\n",
    "\n",
    "#### Prepare video embeddings\n"
   ],
   "id": "3e1fd17507d53b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:42.315503Z",
     "start_time": "2025-05-14T14:52:42.099382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine all tags into a flat list to get unique values\n",
    "all_tags = set(tag for tags in video_metadata['feat'].tolist() +\n",
    "                         user_features['preferred_category'].tolist() +\n",
    "                         user_features['friends_preferred_category'].tolist() for tag in tags)\n",
    "print(f\"Unique tags: {len(all_tags)}\")\n",
    "print(user_features.head())\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=sorted(all_tags))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "print(user_features)\n",
    "# Encode video tags\n",
    "print(\"Encoding video tags...\")\n",
    "video_tag_matrix = mlb.fit_transform(video_metadata['feat'])\n",
    "video_ids = video_metadata['video_id'].values\n",
    "\n",
    "# Encode user preferences (we'll combine preferred and friends_preferred)\n",
    "user_combined_tags = user_features.apply(\n",
    "    lambda row: list(set(row['preferred_category'] + row['friends_preferred_category'])), axis=1\n",
    ")\n",
    "print(\"Encoding user tags...\")\n",
    "user_tag_matrix = mlb.transform(user_combined_tags)\n",
    "user_ids = user_features['user_id'].values"
   ],
   "id": "d4605abb0ba08e0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags: 31\n",
      "   user_id user_active_degree  is_lowactive_period  is_live_streamer  \\\n",
      "0        0        high_active                    0                 0   \n",
      "1        1        full_active                    0                 0   \n",
      "2        2        full_active                    0                 0   \n",
      "3        3        full_active                    0                 0   \n",
      "4        4        full_active                    0                 0   \n",
      "\n",
      "   is_video_author  follow_user_num follow_user_num_range  fans_user_num  \\\n",
      "0                0                5                (0,10]              0   \n",
      "1                0              386             (250,500]              4   \n",
      "2                0               27               (10,50]              0   \n",
      "3                0               16               (10,50]              0   \n",
      "4                0              122             (100,150]              4   \n",
      "\n",
      "  fans_user_num_range  friend_user_num  ... onehot_feat15  onehot_feat16  \\\n",
      "0                   0                0  ...             0              0   \n",
      "1              [1,10)                2  ...             0              0   \n",
      "2                   0                0  ...             0              0   \n",
      "3                   0                0  ...             0              0   \n",
      "4              [1,10)                0  ...             0              0   \n",
      "\n",
      "  onehot_feat17  friend_list  total_videos_watched  avg_watch_ratio  \\\n",
      "0             0          NaN                  2190         1.096715   \n",
      "1             0          NaN                  1297         0.973592   \n",
      "2             0          NaN                   976         0.659484   \n",
      "3             0          NaN                  2784         0.905726   \n",
      "4             0          NaN                   511         0.831778   \n",
      "\n",
      "   preferred_category  user_activity_level  num_friends  \\\n",
      "0                [28]                 2190            0   \n",
      "1                [28]                 1297            0   \n",
      "2                [12]                  976            0   \n",
      "3                [28]                 2784            0   \n",
      "4                [26]                  511            0   \n",
      "\n",
      "   friends_preferred_category  \n",
      "0                        [28]  \n",
      "1                        [28]  \n",
      "2                        [12]  \n",
      "3                        [28]  \n",
      "4                        [26]  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "      user_id user_active_degree  is_lowactive_period  is_live_streamer  \\\n",
      "0           0        high_active                    0                 0   \n",
      "1           1        full_active                    0                 0   \n",
      "2           2        full_active                    0                 0   \n",
      "3           3        full_active                    0                 0   \n",
      "4           4        full_active                    0                 0   \n",
      "...       ...                ...                  ...               ...   \n",
      "7171     7171        full_active                    0                 0   \n",
      "7172     7172        full_active                    0                 0   \n",
      "7173     7173        full_active                    0                 0   \n",
      "7174     7174        full_active                    0                 0   \n",
      "7175     7175        full_active                    0                 0   \n",
      "\n",
      "      is_video_author  follow_user_num follow_user_num_range  fans_user_num  \\\n",
      "0                   0                5                (0,10]              0   \n",
      "1                   0              386             (250,500]              4   \n",
      "2                   0               27               (10,50]              0   \n",
      "3                   0               16               (10,50]              0   \n",
      "4                   0              122             (100,150]              4   \n",
      "...               ...              ...                   ...            ...   \n",
      "7171                1               52              (50,100]              1   \n",
      "7172                0               45               (10,50]              2   \n",
      "7173                0              615                  500+              3   \n",
      "7174                0              959                  500+              0   \n",
      "7175                1               98             (100,150]             35   \n",
      "\n",
      "     fans_user_num_range  friend_user_num  ... onehot_feat15  onehot_feat16  \\\n",
      "0                      0                0  ...             0              0   \n",
      "1                 [1,10)                2  ...             0              0   \n",
      "2                      0                0  ...             0              0   \n",
      "3                      0                0  ...             0              0   \n",
      "4                 [1,10)                0  ...             0              0   \n",
      "...                  ...              ...  ...           ...            ...   \n",
      "7171              [1,10)                0  ...             0              0   \n",
      "7172              [1,10)                2  ...             0              0   \n",
      "7173              [1,10)                2  ...             0              0   \n",
      "7174                   0                0  ...             0              0   \n",
      "7175            [10,100)               33  ...             0              0   \n",
      "\n",
      "     onehot_feat17  friend_list  total_videos_watched  avg_watch_ratio  \\\n",
      "0                0          NaN                  2190         1.096715   \n",
      "1                0          NaN                  1297         0.973592   \n",
      "2                0          NaN                   976         0.659484   \n",
      "3                0          NaN                  2784         0.905726   \n",
      "4                0          NaN                   511         0.831778   \n",
      "...            ...          ...                   ...              ...   \n",
      "7171             0          NaN                  1195         0.992108   \n",
      "7172             0          NaN                  1833         1.140360   \n",
      "7173             0          NaN                   743         1.113676   \n",
      "7174             0       [6571]                  1543         0.763685   \n",
      "7175             0          NaN                  1544         1.369951   \n",
      "\n",
      "      preferred_category  user_activity_level  num_friends  \\\n",
      "0                   [28]                 2190            0   \n",
      "1                   [28]                 1297            0   \n",
      "2                   [12]                  976            0   \n",
      "3                   [28]                 2784            0   \n",
      "4                   [26]                  511            0   \n",
      "...                  ...                  ...          ...   \n",
      "7171                [17]                 1195            0   \n",
      "7172                [28]                 1833            0   \n",
      "7173                [28]                  743            0   \n",
      "7174                [28]                 1543            0   \n",
      "7175                [28]                 1544            0   \n",
      "\n",
      "      friends_preferred_category  \n",
      "0                           [28]  \n",
      "1                           [28]  \n",
      "2                           [12]  \n",
      "3                           [28]  \n",
      "4                           [26]  \n",
      "...                          ...  \n",
      "7171                        [17]  \n",
      "7172                        [28]  \n",
      "7173                        [28]  \n",
      "7174                        [28]  \n",
      "7175                        [28]  \n",
      "\n",
      "[7176 rows x 38 columns]\n",
      "Encoding video tags...\n",
      "Encoding user tags...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute recommendations",
   "id": "4017800eae214252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:48.846951Z",
     "start_time": "2025-05-14T14:52:42.333255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Computing recommendations...\")\n",
    "\n",
    "# Compute cosine similarity: users x videos\n",
    "#similarity_matrix = cosine_similarity(user_tag_matrix, video_tag_matrix)\n",
    "similarity_matrix = cosine_similarity(user_tag_matrix, video_tag_matrix)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n"
   ],
   "id": "8f556b062475620d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing recommendations...\n",
      "Similarity matrix shape: (7176, 343341)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:53:30.042191Z",
     "start_time": "2025-05-14T14:52:48.909374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def recommend_top_n(sim_matrix, video_ids, top_n=5):\n",
    "    recommendations_cb = {}\n",
    "    for user_idx, sims in enumerate(sim_matrix):\n",
    "        top_indices = np.argsort(sims)[::-1]\n",
    "        unique_recs = []\n",
    "        seen = set()\n",
    "        for idx in top_indices:\n",
    "            vid = video_ids[idx]\n",
    "            if vid not in seen:\n",
    "                unique_recs.append(vid)\n",
    "                seen.add(vid)\n",
    "            if len(unique_recs) == top_n:\n",
    "                break\n",
    "        recommendations_cb[user_ids[user_idx]] = unique_recs\n",
    "    return recommendations_cb\n",
    "\n",
    "top_n = 10  # Number of videos to recommend per user\n",
    "recommendations = recommend_top_n(similarity_matrix, video_ids, top_n)"
   ],
   "id": "81f4e335ac851063",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hybridization",
   "id": "935fb75a51c88f27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:55:17.191923Z",
     "start_time": "2025-05-14T14:53:30.093089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize popularity\n",
    "video_metadata['normalized_popularity'] = (\n",
    "    (video_metadata['like_cnt'] - video_metadata['like_cnt'].min()) /\n",
    "    (video_metadata['like_cnt'].max() - video_metadata['like_cnt'].min())\n",
    ")\n",
    "popularity_scores = video_metadata.set_index('video_id')['normalized_popularity'].reindex(video_ids).fillna(0).values\n",
    "\n",
    "def recommend_top_n_hybrid(sim_matrix, video_ids, popularity_scores, alpha=0.7, top_n=10):\n",
    "    recommendations = {}\n",
    "    for user_idx, sims in enumerate(sim_matrix):\n",
    "        # Blend content similarity with popularity\n",
    "        final_scores = alpha * sims + (1 - alpha) * popularity_scores\n",
    "\n",
    "        top_indices = np.argsort(final_scores)[::-1]\n",
    "        unique_recs = []\n",
    "        seen = set()\n",
    "        for idx in top_indices:\n",
    "            vid = video_ids[idx]\n",
    "            if vid not in seen:\n",
    "                unique_recs.append(vid)\n",
    "                seen.add(vid)\n",
    "            if len(unique_recs) == top_n:\n",
    "                break\n",
    "        recommendations[user_ids[user_idx]] = unique_recs\n",
    "    return recommendations\n",
    "\n",
    "recommendations_hybrid = recommend_top_n_hybrid(similarity_matrix, video_ids, popularity_scores, alpha=0.7, top_n=top_n)"
   ],
   "id": "90bf2dd7f34d7a87",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Network",
   "id": "f1e78f5edc586974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:05.337382Z",
     "start_time": "2025-05-14T14:55:17.253911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Neural network recommender with embeddings for one-hot features\n",
    "# Define a PyTorch Dataset class\n",
    "class RecSysDataset(Dataset):\n",
    "    def __init__(self, interactions, user_features_df, video_features_df):\n",
    "        self.user_map = user_features_df.set_index('user_id')\n",
    "        self.video_map = video_features_df.set_index('video_id')\n",
    "\n",
    "        self.onehot_feats = [f'onehot_feat{i}' for i in range(1, 18)]\n",
    "        self.samples = []\n",
    "\n",
    "        time_begin = datetime.datetime.now()\n",
    "\n",
    "        expected_user_feat_len = len(self.onehot_feats)\n",
    "        for idx, row in interactions.iterrows():\n",
    "            if idx % 100000 == 0:\n",
    "                print(f\"Processed {idx} rows\")\n",
    "            if idx % 1000000 == 0:\n",
    "                print(f\"Processed {idx} rows, elapsed time: {datetime.datetime.now() - time_begin}\")\n",
    "                time_begin = datetime.datetime.now()\n",
    "            user_id = row['user_id']\n",
    "            video_id = row['video_id']\n",
    "\n",
    "            if user_id not in self.user_map.index or video_id not in self.video_map.index:\n",
    "                continue\n",
    "\n",
    "            user_feat = self.user_map.loc[user_id]\n",
    "            video_feat = self.video_map.loc[video_id]\n",
    "\n",
    "            # Ensure all onehot_feats are present and ordered, fill missing with 0\n",
    "            user_input = user_feat.reindex(self.onehot_feats).infer_objects(copy=False).fillna(0).astype(int).to_numpy()\n",
    "            user_input = np.clip(user_input, a_min=0, a_max=None)\n",
    "\n",
    "            video_input = np.array([video_feat['video_tag_id']], dtype=np.int64)\n",
    "\n",
    "            # Check input sizes\n",
    "            if user_input.shape[0] != expected_user_feat_len:\n",
    "                continue  # Skip malformed user input\n",
    "\n",
    "            x = np.concatenate([user_input, video_input.flatten()])\n",
    "\n",
    "            # Extra safety check\n",
    "            if x.shape[0] != expected_user_feat_len + 1:\n",
    "                continue  # Skip malformed total input\n",
    "\n",
    "            y = 1.0 if row['watch_ratio'] > 0.5 else 0.0\n",
    "            self.samples.append((x, y))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.samples[idx][0], dtype=torch.long), torch.tensor(self.samples[idx][1], dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(\"After class RecSysDataset\")\n",
    "# Neural net with embeddings\n",
    "class RecNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecNN, self).__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(8, 4),     # onehot_feat1\n",
    "            nn.Embedding(30, 8),    # onehot_feat2\n",
    "            nn.Embedding(1076, 32), # onehot_feat3\n",
    "            nn.Embedding(12, 4),\n",
    "            nn.Embedding(10, 4),\n",
    "            nn.Embedding(3, 2),\n",
    "            nn.Embedding(47, 6),\n",
    "            nn.Embedding(340, 16),\n",
    "            nn.Embedding(7, 4),\n",
    "            nn.Embedding(5, 3),\n",
    "            nn.Embedding(3, 2),\n",
    "            nn.Embedding(2, 2),\n",
    "            nn.Embedding(2, 2),\n",
    "            nn.Embedding(2, 2),\n",
    "            nn.Embedding(2, 2),\n",
    "            nn.Embedding(2, 2),\n",
    "            nn.Embedding(2, 2),\n",
    "            nn.Embedding(2892, 32)  # video_tag_id, adjust range as needed\n",
    "        ])\n",
    "\n",
    "\n",
    "        total_emb_size = sum(emb.embedding_dim for emb in self.embeddings)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(total_emb_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, emb in enumerate(self.embeddings):\n",
    "            max_index = emb.num_embeddings\n",
    "            col_vals = x[:, i]\n",
    "            if (col_vals >= max_index).any() or (col_vals < 0).any():\n",
    "                print(f\"[ERROR] Embedding {i}: min = {col_vals.min().item()}, max = {col_vals.max().item()}\")\n",
    "\n",
    "        embedded = [emb(x[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(embedded, dim=1)\n",
    "        return self.model(x_cat)\n",
    "\n",
    "print(\"After class RecNN\")\n",
    "# Prepare dataset and model\n",
    "# TODO: Align features and normalize/encode any continuous features if used\n",
    "train_dataset = RecSysDataset(interactions_train[:200000], user_features, video_metadata)\n",
    "print(\"After train_dataset\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "print(\"After train_loader\")\n",
    "model = RecNN()\n",
    "\n",
    "print(\"After model\")\n",
    "# Training setup\n",
    "criterion = nn.BCELoss()\n",
    "print(\"After criterion\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"After optimizer\")\n",
    "# Training loop\n",
    "for epoch in range(5):  # Keep epochs small for lightweight computing\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
    "print(\"Finished!\")\n",
    "# Generate top-N recommendations for each user\n",
    "def generate_recommendations(model, user_features_df, video_metadata_df, N=10):\n",
    "    model.eval()\n",
    "    recommendations = {}\n",
    "    video_ids = video_metadata_df['video_id'].values\n",
    "    video_tags = video_metadata_df['video_tag_id'].infer_objects(copy=False).fillna(0).astype(int).values\n",
    "\n",
    "    # Prepare user features\n",
    "    begin = datetime.datetime.now()\n",
    "    for _, user_row in user_features_df.iterrows():\n",
    "        user_id = user_row['user_id']\n",
    "        if user_id % 100 == 0:\n",
    "            print(f\"{user_id}/{user_features_df.shape[0]} users processed in {datetime.datetime.now() - begin}\")\n",
    "        onehot_feats = [f'onehot_feat{i}' for i in range(1, 18)]\n",
    "        user_input = user_row[onehot_feats].infer_objects(copy=False).fillna(0).to_numpy(dtype=np.int64)\n",
    "\n",
    "        inputs = []\n",
    "        for tag in video_tags:\n",
    "            x = np.concatenate([user_input, [tag]])\n",
    "            inputs.append(x)\n",
    "\n",
    "        inputs_tensor = torch.tensor(np.array(inputs), dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            scores = model(inputs_tensor).squeeze().numpy()\n",
    "\n",
    "        top_indices = np.argsort(scores)[-N:][::-1]\n",
    "        recommended_videos = video_ids[top_indices]\n",
    "        recommendations[user_id] = recommended_videos.tolist()\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "nn_recommendations = generate_recommendations(model, user_features[:500], video_metadata, N=30)\n"
   ],
   "id": "e58495ddab16e0d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After class RecSysDataset\n",
      "After class RecNN\n",
      "Processed 0 rows\n",
      "Processed 0 rows, elapsed time: 0:00:00.115620\n",
      "Processed 100000 rows\n",
      "After train_dataset\n",
      "After train_loader\n",
      "After model\n",
      "After criterion\n",
      "After optimizer\n",
      "Epoch 1, Loss: 0.6804\n",
      "Epoch 2, Loss: 0.6731\n",
      "Epoch 3, Loss: 0.6665\n",
      "Epoch 4, Loss: 0.6606\n",
      "Epoch 5, Loss: 0.6552\n",
      "Finished!\n",
      "0/500 users processed in 0:00:00.000524\n",
      "100/500 users processed in 0:00:48.751895\n",
      "200/500 users processed in 0:01:36.982012\n",
      "300/500 users processed in 0:02:25.206804\n",
      "400/500 users processed in 0:03:13.335605\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:58.644935Z",
     "start_time": "2025-05-14T15:00:05.386938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ground_truth = defaultdict(set)\n",
    "for _, row in interactions_test.iterrows():\n",
    "    ground_truth[row['user_id']].add(row['video_id'])\n",
    "\n",
    "def evaluate_recommendations(recommendations, ground_truth, k=20):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    hit_count = 0\n",
    "    user_count = 0\n",
    "    for user_id, recs in recommendations.items():\n",
    "        if user_id not in ground_truth:\n",
    "            continue  # No test data for this user\n",
    "        true_items = ground_truth[user_id]\n",
    "        recommended_items = recs[:k]\n",
    "        hits = len(set(recommended_items) & true_items)\n",
    "        precision = hits / k\n",
    "        recall = hits / len(true_items) if len(true_items) > 0 else 0\n",
    "        hit = 1 if hits > 0 else 0\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        hit_count += hit\n",
    "        user_count += 1\n",
    "\n",
    "    precision_at_k = np.mean(precision_list)\n",
    "    recall_at_k = np.mean(recall_list)\n",
    "    hit_rate = hit_count / user_count if user_count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'Precision@K': precision_at_k,\n",
    "        'Recall@K': recall_at_k,\n",
    "        'HitRate@K': hit_rate,\n",
    "        'Evaluated Users': user_count\n",
    "    }\n",
    "\n",
    "# Evaluate content-based recommendations\n",
    "content_based_results = evaluate_recommendations(recommendations_hybrid, ground_truth, k=30)\n",
    "print('Content-Based Evaluation Results:', content_based_results)\n",
    "\n",
    "# Evaluate ALS recommendations\n",
    "als_results = evaluate_recommendations(als_recommendations, ground_truth, k=30)\n",
    "print('ALS Evaluation Results:', als_results)\n",
    "\n",
    "# Evaluate ALS recommendations\n",
    "nn_results = evaluate_recommendations(nn_recommendations, ground_truth, k=30)\n",
    "print('NN Evaluation Results:', nn_results)"
   ],
   "id": "8fc8d2e845acb2f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Evaluation Results: {'Precision@K': np.float64(0.03939056112969156), 'Recall@K': np.float64(0.0031613462128858875), 'HitRate@K': 0.6885451505016722, 'Evaluated Users': 7176}\n",
      "ALS Evaluation Results: {'Precision@K': np.float64(0.02900408769973987), 'Recall@K': np.float64(0.002589262589964959), 'HitRate@K': 0.8701226309921962, 'Evaluated Users': 7176}\n",
      "NN Evaluation Results: {'Precision@K': np.float64(0.004733333333333333), 'Recall@K': np.float64(0.00036201210006546437), 'HitRate@K': 0.124, 'Evaluated Users': 500}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Save recommendations",
   "id": "c71421965b685df2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:58.747278Z",
     "start_time": "2025-05-14T15:00:58.660657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nSample Recommendations:\")\n",
    "for uid in list(recommendations_hybrid.keys())[:5]:\n",
    "    print(f\"User {uid} recommendations: {recommendations[uid]}\")\n",
    "\n",
    "# save to CSV\n",
    "def save_recommendations(recommendations, filename):\n",
    "    # Create a DataFrame from the recommendations dictionary\n",
    "    df = pd.DataFrame.from_dict(recommendations, orient='index')\n",
    "    # Reset index to make user_id a column\n",
    "    df = df.reset_index()\n",
    "    # Rename the index column to user_id\n",
    "    df = df.rename(columns={'index': 'user_id'})\n",
    "    # Save to CSV\n",
    "    df.to_csv(os.path.join(processed_path, filename), index=False)\n",
    "\n",
    "save_recommendations(recommendations_hybrid, \"content_based_recommendations.csv\")\n",
    "\n",
    "save_recommendations(recommendations, \"als_recommendations.csv\")\n",
    "\n",
    "save_recommendations(nn_recommendations, \"nn_recommendations.csv\")"
   ],
   "id": "148dfe5b786d043b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Recommendations:\n",
      "User 0 recommendations: [np.int64(8699), np.int64(9436), np.int64(5567), np.int64(7716), np.int64(2073), np.int64(9433), np.int64(9431), np.int64(652), np.int64(649), np.int64(663)]\n",
      "User 1 recommendations: [np.int64(8699), np.int64(9436), np.int64(5567), np.int64(7716), np.int64(2073), np.int64(9433), np.int64(9431), np.int64(652), np.int64(649), np.int64(663)]\n",
      "User 2 recommendations: [np.int64(9121), np.int64(3793), np.int64(9064), np.int64(5375), np.int64(9060), np.int64(6839), np.int64(9540), np.int64(464), np.int64(4434), np.int64(6028)]\n",
      "User 3 recommendations: [np.int64(8699), np.int64(9436), np.int64(5567), np.int64(7716), np.int64(2073), np.int64(9433), np.int64(9431), np.int64(652), np.int64(649), np.int64(663)]\n",
      "User 4 recommendations: [np.int64(280), np.int64(1884), np.int64(4590), np.int64(684), np.int64(6204), np.int64(1889), np.int64(3096), np.int64(4026), np.int64(1865), np.int64(5663)]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save the Trained Models",
   "id": "753f37e0981757a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:59.037449Z",
     "start_time": "2025-05-14T15:00:59.012842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the ALS model\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(processed_path, 'als_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(als_model, f)\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ],
   "id": "4e0c1033ba6b2a43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
