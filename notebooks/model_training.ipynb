{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:47:18.729809Z",
     "start_time": "2025-05-16T09:47:17.566235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.evaluation import precision_at_k, ndcg_at_k, mean_average_precision_at_k\n",
    "from src.utils.utils import safe_parse_feat\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.utils.RecNN import RecNN\n"
   ],
   "id": "7be6823d77d8a33a",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpairwise\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cosine_similarity\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m csr_matrix\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TfidfTransformer\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/sklearn/__init__.py:73\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: F401 E402\u001B[39;00m\n\u001B[1;32m     70\u001B[0m     __check_build,\n\u001B[1;32m     71\u001B[0m     _distributor_init,\n\u001B[1;32m     72\u001B[0m )\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_show_versions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m show_versions  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[1;32m     76\u001B[0m _submodules \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalibration\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompose\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    115\u001B[0m ]\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/sklearn/base.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InconsistentVersionWarning\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_metadata_requests\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _MetadataRequester, _routing_enabled\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m validate_parameter_constraints\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/sklearn/utils/__init__.py:15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _joblib, metadata_routing\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_bunch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Bunch\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_chunking\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gen_batches, gen_even_slices\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# `_` in its name.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/sklearn/utils/_chunking.py:11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_config\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval, validate_params\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mchunk_generator\u001B[39m(gen, chunksize):\n\u001B[1;32m     15\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:17\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m csr_matrix, issparse\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvalidation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _is_arraylike_not_scalar\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mInvalidParameterError\u001B[39;00m(\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[1;32m     21\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03m    does not have a valid type or value.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/sklearn/utils/validation.py:24\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdeprecation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _deprecate_force_all_finite\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfixes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_isfinite\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FiniteStatus, cy_isfinite\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tags\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_tags\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfixes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _object_dtype_isnan\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:398\u001B[0m, in \u001B[0;36mparent\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the Data",
   "id": "f3d4d8bd2ed08e1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:13:09.566252Z",
     "start_time": "2025-05-16T09:12:54.771852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the path to the processed data\n",
    "processed_path = \"../data/processed/\"\n",
    "\n",
    "# Load the processed datasets\n",
    "interactions_train = pd.read_csv(os.path.join(processed_path, \"interactions_train.csv\"))\n",
    "interactions_test = pd.read_csv(os.path.join(processed_path, \"interactions_test.csv\"))\n",
    "user_features = pd.read_csv(os.path.join(processed_path, \"user_features.csv\"))\n",
    "video_metadata = pd.read_csv(os.path.join(processed_path, \"video_metadata.csv\"))\n",
    "\n",
    "video_metadata[\"feat\"] = video_metadata[\"feat\"].apply(safe_parse_feat)\n",
    "video_metadata = video_metadata[video_metadata[\"feat\"].notnull()]\n",
    "\n",
    "user_features[\"preferred_category\"] = user_features[\"preferred_category\"].apply(safe_parse_feat)\n",
    "user_features = user_features[user_features[\"preferred_category\"].notnull()]\n",
    "\n",
    "user_features[\"friends_preferred_category\"] = user_features[\"friends_preferred_category\"].apply(safe_parse_feat)\n",
    "user_features = user_features[user_features[\"friends_preferred_category\"].notnull()]"
   ],
   "id": "40244dfd9ccd2683",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collaborative Filtering with ALS",
   "id": "ad7a5b654ae7a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:14:54.255574Z",
     "start_time": "2025-05-16T09:13:09.665418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the interaction matrix\n",
    "interaction_matrix = csr_matrix((interactions_train['watch_ratio'],\n",
    "                                 (interactions_train['user_id'], interactions_train['video_id'])))\n",
    "\n",
    "# Create the test interaction matrix\n",
    "test_interaction_matrix = csr_matrix((interactions_test['watch_ratio'],\n",
    "                                      (interactions_test['user_id'], interactions_test['video_id'])))\n",
    "\n",
    "# Initialize the ALS model\n",
    "als_model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
    "\n",
    "# Train the ALS model\n",
    "als_model.fit(interaction_matrix)"
   ],
   "id": "ed9a49d7ba1fbe69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jules_/Desktop/Epita/Algo/recommender_system_project/lib/python3.9/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 20/20 [01:43<00:00,  5.18s/it]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate the ALS Model",
   "id": "c655e6c961b40176"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:14:55.727340Z",
     "start_time": "2025-05-16T09:14:54.277933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Precision@K and Recall@K\n",
    "K = 30\n",
    "ndcg = ndcg_at_k(als_model, interaction_matrix, test_interaction_matrix, int_K=K, show_progress=True, int_num_threads=1)\n",
    "ma_precision = mean_average_precision_at_k(als_model, interaction_matrix, test_interaction_matrix, int_K=K, show_progress=True, int_num_threads=1)\n",
    "precision = precision_at_k(als_model, interaction_matrix, test_interaction_matrix, int_K=K, show_progress=True, int_num_threads=1)\n",
    "\n",
    "print(f\"NDCG@{K}: {ndcg} - Best for position-aware ranking quality.\")\n",
    "print(f\"MAP@{K}: {ma_precision} – Great global ranking evaluation.\")\n",
    "print(f\"Precision@{K}: {precision} - Simple and intuitive.\")"
   ],
   "id": "ff8329dff163fce1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7176/7176 [00:00<00:00, 13371.57it/s]\n",
      "100%|██████████| 7176/7176 [00:00<00:00, 16109.02it/s]\n",
      "100%|██████████| 7176/7176 [00:00<00:00, 15646.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@30: 0.8049591525105662 - Best for position-aware ranking quality.\n",
      "MAP@30: 0.6872343248485162 – Great global ranking evaluation.\n",
      "Precision@30: 0.7890308883716824 - Simple and intuitive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Content-Based Filtering with and Cosine Similarity\n",
    "\n",
    "#### Prepare video embeddings\n"
   ],
   "id": "3e1fd17507d53b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:14:55.975571Z",
     "start_time": "2025-05-16T09:14:55.740782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine all tags into a flat list to get unique values\n",
    "all_tags = set(tag for tags in video_metadata['feat'].tolist() +\n",
    "                         user_features['preferred_category'].tolist() +\n",
    "                         user_features['friends_preferred_category'].tolist() for tag in tags)\n",
    "print(f\"Unique tags: {len(all_tags)}\")\n",
    "print(user_features.head())\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=sorted(all_tags))\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "print(user_features)\n",
    "# Encode video tags\n",
    "print(\"Encoding video tags...\")\n",
    "video_tag_matrix = mlb.fit_transform(video_metadata['feat'])\n",
    "video_ids = video_metadata['video_id'].values\n",
    "\n",
    "# Encode user preferences (we'll combine preferred and friends_preferred)\n",
    "user_combined_tags = user_features.apply(\n",
    "    lambda row: list(set(row['preferred_category'] + row['friends_preferred_category'])), axis=1\n",
    ")\n",
    "print(\"Encoding user tags...\")\n",
    "user_tag_matrix = mlb.transform(user_combined_tags)\n",
    "user_ids = user_features['user_id'].values"
   ],
   "id": "d4605abb0ba08e0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags: 31\n",
      "   user_id user_active_degree  is_lowactive_period  is_live_streamer  \\\n",
      "0        0        high_active                    0                 0   \n",
      "1        1        full_active                    0                 0   \n",
      "2        2        full_active                    0                 0   \n",
      "3        3        full_active                    0                 0   \n",
      "4        4        full_active                    0                 0   \n",
      "\n",
      "   is_video_author  follow_user_num follow_user_num_range  fans_user_num  \\\n",
      "0                0                5                (0,10]              0   \n",
      "1                0              386             (250,500]              4   \n",
      "2                0               27               (10,50]              0   \n",
      "3                0               16               (10,50]              0   \n",
      "4                0              122             (100,150]              4   \n",
      "\n",
      "  fans_user_num_range  friend_user_num  ... onehot_feat14  onehot_feat15  \\\n",
      "0                   0                0  ...             0              0   \n",
      "1              [1,10)                2  ...             0              0   \n",
      "2                   0                0  ...             0              0   \n",
      "3                   0                0  ...             0              0   \n",
      "4              [1,10)                0  ...             0              0   \n",
      "\n",
      "  onehot_feat16  onehot_feat17  friend_list  total_videos_watched  \\\n",
      "0             0              0          NaN                  2190   \n",
      "1             0              0          NaN                  1297   \n",
      "2             0              0          NaN                   976   \n",
      "3             0              0          NaN                  2784   \n",
      "4             0              0          NaN                   511   \n",
      "\n",
      "   avg_watch_ratio  preferred_category  num_friends  \\\n",
      "0         1.096715                [28]            0   \n",
      "1         0.973592                [28]            0   \n",
      "2         0.659484                [12]            0   \n",
      "3         0.905726                [28]            0   \n",
      "4         0.831778                [26]            0   \n",
      "\n",
      "   friends_preferred_category  \n",
      "0                        [28]  \n",
      "1                        [28]  \n",
      "2                        [12]  \n",
      "3                        [28]  \n",
      "4                        [26]  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "      user_id user_active_degree  is_lowactive_period  is_live_streamer  \\\n",
      "0           0        high_active                    0                 0   \n",
      "1           1        full_active                    0                 0   \n",
      "2           2        full_active                    0                 0   \n",
      "3           3        full_active                    0                 0   \n",
      "4           4        full_active                    0                 0   \n",
      "...       ...                ...                  ...               ...   \n",
      "7171     7171        full_active                    0                 0   \n",
      "7172     7172        full_active                    0                 0   \n",
      "7173     7173        full_active                    0                 0   \n",
      "7174     7174        full_active                    0                 0   \n",
      "7175     7175        full_active                    0                 0   \n",
      "\n",
      "      is_video_author  follow_user_num follow_user_num_range  fans_user_num  \\\n",
      "0                   0                5                (0,10]              0   \n",
      "1                   0              386             (250,500]              4   \n",
      "2                   0               27               (10,50]              0   \n",
      "3                   0               16               (10,50]              0   \n",
      "4                   0              122             (100,150]              4   \n",
      "...               ...              ...                   ...            ...   \n",
      "7171                1               52              (50,100]              1   \n",
      "7172                0               45               (10,50]              2   \n",
      "7173                0              615                  500+              3   \n",
      "7174                0              959                  500+              0   \n",
      "7175                1               98             (100,150]             35   \n",
      "\n",
      "     fans_user_num_range  friend_user_num  ... onehot_feat14  onehot_feat15  \\\n",
      "0                      0                0  ...             0              0   \n",
      "1                 [1,10)                2  ...             0              0   \n",
      "2                      0                0  ...             0              0   \n",
      "3                      0                0  ...             0              0   \n",
      "4                 [1,10)                0  ...             0              0   \n",
      "...                  ...              ...  ...           ...            ...   \n",
      "7171              [1,10)                0  ...             0              0   \n",
      "7172              [1,10)                2  ...             0              0   \n",
      "7173              [1,10)                2  ...             0              0   \n",
      "7174                   0                0  ...             0              0   \n",
      "7175            [10,100)               33  ...             0              0   \n",
      "\n",
      "     onehot_feat16  onehot_feat17  friend_list  total_videos_watched  \\\n",
      "0                0              0          NaN                  2190   \n",
      "1                0              0          NaN                  1297   \n",
      "2                0              0          NaN                   976   \n",
      "3                0              0          NaN                  2784   \n",
      "4                0              0          NaN                   511   \n",
      "...            ...            ...          ...                   ...   \n",
      "7171             0              0          NaN                  1195   \n",
      "7172             0              0          NaN                  1833   \n",
      "7173             0              0          NaN                   743   \n",
      "7174             0              0       [6571]                  1543   \n",
      "7175             0              0          NaN                  1544   \n",
      "\n",
      "      avg_watch_ratio  preferred_category  num_friends  \\\n",
      "0            1.096715                [28]            0   \n",
      "1            0.973592                [28]            0   \n",
      "2            0.659484                [12]            0   \n",
      "3            0.905726                [28]            0   \n",
      "4            0.831778                [26]            0   \n",
      "...               ...                 ...          ...   \n",
      "7171         0.992108                [17]            0   \n",
      "7172         1.140360                [28]            0   \n",
      "7173         1.113676                [28]            0   \n",
      "7174         0.763685                [28]            0   \n",
      "7175         1.369951                [28]            0   \n",
      "\n",
      "      friends_preferred_category  \n",
      "0                           [28]  \n",
      "1                           [28]  \n",
      "2                           [12]  \n",
      "3                           [28]  \n",
      "4                           [26]  \n",
      "...                          ...  \n",
      "7171                        [17]  \n",
      "7172                        [28]  \n",
      "7173                        [28]  \n",
      "7174                        [28]  \n",
      "7175                        [28]  \n",
      "\n",
      "[7176 rows x 37 columns]\n",
      "Encoding video tags...\n",
      "Encoding user tags...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Compute recommendations",
   "id": "4017800eae214252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:15:02.794398Z",
     "start_time": "2025-05-16T09:14:55.989901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Computing recommendations...\")\n",
    "\n",
    "# Compute cosine similarity: users x videos\n",
    "#similarity_matrix = cosine_similarity(user_tag_matrix, video_tag_matrix)\n",
    "similarity_matrix = cosine_similarity(user_tag_matrix, video_tag_matrix)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n"
   ],
   "id": "8f556b062475620d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing recommendations...\n",
      "Similarity matrix shape: (7176, 343341)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Network",
   "id": "f1e78f5edc586974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:19:49.149500Z",
     "start_time": "2025-05-16T09:15:02.848398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Neural network recommender with embeddings for one-hot features\n",
    "# Define a PyTorch Dataset class\n",
    "class RecSysDataset(Dataset):\n",
    "    def __init__(self, interactions, user_features_df, video_features_df):\n",
    "        self.user_map = user_features_df.set_index('user_id')\n",
    "        self.video_map = video_features_df.set_index('video_id')\n",
    "\n",
    "        self.onehot_feats = [f'onehot_feat{i}' for i in range(1, 18)]\n",
    "        self.samples = []\n",
    "\n",
    "        time_begin = datetime.datetime.now()\n",
    "\n",
    "        expected_user_feat_len = len(self.onehot_feats)\n",
    "        for idx, row in interactions.iterrows():\n",
    "            if idx % 100000 == 0:\n",
    "                print(f\"Processed {idx} rows\")\n",
    "            if idx % 1000000 == 0:\n",
    "                print(f\"Processed {idx} rows, elapsed time: {datetime.datetime.now() - time_begin}\")\n",
    "                time_begin = datetime.datetime.now()\n",
    "            user_id = row['user_id']\n",
    "            video_id = row['video_id']\n",
    "\n",
    "            if user_id not in self.user_map.index or video_id not in self.video_map.index:\n",
    "                continue\n",
    "\n",
    "            user_feat = self.user_map.loc[user_id]\n",
    "            video_feat = self.video_map.loc[video_id]\n",
    "\n",
    "            # Ensure all onehot_feats are present and ordered, fill missing with 0\n",
    "            user_input = user_feat.reindex(self.onehot_feats).infer_objects(copy=False).fillna(0).astype(int).to_numpy()\n",
    "            user_input = np.clip(user_input, a_min=0, a_max=None)\n",
    "\n",
    "            video_input = np.array([video_feat['video_tag_id']], dtype=np.int64)\n",
    "\n",
    "            # Check input sizes\n",
    "            if user_input.shape[0] != expected_user_feat_len:\n",
    "                continue  # Skip malformed user input\n",
    "\n",
    "            x = np.concatenate([user_input, video_input.flatten()])\n",
    "\n",
    "            # Extra safety check\n",
    "            if x.shape[0] != expected_user_feat_len + 1:\n",
    "                continue  # Skip malformed total input\n",
    "\n",
    "            y = 1.0 if row['watch_ratio'] > 0.5 else 0.0\n",
    "            self.samples.append((x, y))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.samples[idx][0], dtype=torch.long), torch.tensor(self.samples[idx][1], dtype=torch.float32)\n",
    "\n",
    "# Prepare dataset and model\n",
    "print(\"Preparing dataset...\")\n",
    "train_dataset = RecSysDataset(interactions_train[:200000], user_features, video_metadata) # TODO: remove limit\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_dataset = RecSysDataset(interactions_test[:20000], user_features, video_metadata) # TODO: remove limit\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "# Create the model\n",
    "print(\"Creating model...\")\n",
    "model = RecNN()\n",
    "\n",
    "# Training setup\n",
    "print(\"Setting up training...\")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTRAINING STARTED\")\n",
    "for epoch in range(5):  # Keep epochs small for lightweight computing\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
    "print(\"Finished!\")\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        outputs = model(batch_x)\n",
    "        preds = (outputs.squeeze() > 0.5).float()\n",
    "        y_true.extend(batch_y.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1:\", f1_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Generate top-N recommendations for each user\n",
    "def generate_recommendations(model, user_features_df, video_metadata_df, N=10):\n",
    "    model.eval()\n",
    "    recommendations = {}\n",
    "    video_ids = video_metadata_df['video_id'].values\n",
    "    video_tags = video_metadata_df['video_tag_id'].infer_objects(copy=False).fillna(0).astype(int).values\n",
    "\n",
    "    # Prepare user features\n",
    "    begin = datetime.datetime.now()\n",
    "    for _, user_row in user_features_df.iterrows():\n",
    "        user_id = user_row['user_id']\n",
    "        if user_id % 100 == 0:\n",
    "            print(f\"{user_id}/{user_features_df.shape[0]} users processed in {datetime.datetime.now() - begin}\")\n",
    "        onehot_feats = [f'onehot_feat{i}' for i in range(1, 18)]\n",
    "        user_input = user_row[onehot_feats].infer_objects(copy=False).fillna(0).to_numpy(dtype=np.int64)\n",
    "\n",
    "        inputs = []\n",
    "        for tag in video_tags:\n",
    "            x = np.concatenate([user_input, [tag]])\n",
    "            inputs.append(x)\n",
    "\n",
    "        inputs_tensor = torch.tensor(np.array(inputs), dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            scores = model(inputs_tensor).squeeze().numpy()\n",
    "\n",
    "        top_indices = np.argsort(scores)[-N:][::-1]\n",
    "        recommended_videos = video_ids[top_indices]\n",
    "        recommendations[user_id] = recommended_videos.tolist()\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "nn_recommendations = generate_recommendations(model, user_features[:500], video_metadata, N=30) # TODO: remove limit\n"
   ],
   "id": "e58495ddab16e0d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Processed 0 rows\n",
      "Processed 0 rows, elapsed time: 0:00:00.100675\n",
      "Processed 100000 rows\n",
      "Processed 0 rows\n",
      "Processed 0 rows, elapsed time: 0:00:00.007752\n",
      "Creating model...\n",
      "Setting up training...\n",
      "\n",
      "TRAINING STARTED\n",
      "Epoch 1, Loss: 0.7061\n",
      "Epoch 2, Loss: 0.6963\n",
      "Epoch 3, Loss: 0.6872\n",
      "Epoch 4, Loss: 0.6789\n",
      "Epoch 5, Loss: 0.6711\n",
      "Finished!\n",
      "Precision: 0.47058823529411764\n",
      "Recall: 1.0\n",
      "F1: 0.64\n",
      "0/500 users processed in 0:00:00.000378\n",
      "100/500 users processed in 0:00:47.984602\n",
      "200/500 users processed in 0:01:35.474542\n",
      "300/500 users processed in 0:02:22.538598\n",
      "400/500 users processed in 0:03:09.096341\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save the Trained Models",
   "id": "753f37e0981757a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:47:05.742143Z",
     "start_time": "2025-05-16T09:47:05.607019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"../models/\"\n",
    "\n",
    "np.save('similarity_matrix.npy', similarity_matrix)\n",
    "\n",
    "print(\"Similarity matrix saved successfully!\")\n",
    "\n",
    "# Save the ALS model\n",
    "with open(os.path.join(model_path, 'als_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(als_model, f)\n",
    "print(\"ALS model saved successfully!\")\n",
    "\n",
    "# Save the neural network model\n",
    "torch.save(model.state_dict(), os.path.join(model_path, 'nn_model.pth'))\n",
    "print(\"Neural network model saved successfully!\")\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ],
   "id": "4e0c1033ba6b2a43",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m similarity_matrix \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mDataFrame(similarity_matrix, index\u001B[38;5;241m=\u001B[39muser_ids, columns\u001B[38;5;241m=\u001B[39mvideo_ids)\n\u001B[1;32m      4\u001B[0m similarity_matrix\u001B[38;5;241m.\u001B[39mto_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilarity_matrix.csv\u001B[39m\u001B[38;5;124m'\u001B[39m), index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimilarity matrix saved successfully!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
