{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:23:46.797681Z",
     "start_time": "2025-05-16T08:23:45.594349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils.utils import ensure_datetime\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ],
   "id": "7cbf26d045943123",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the datasets",
   "id": "a1d0be699c732622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:24:07.153644Z",
     "start_time": "2025-05-16T08:23:46.801837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the path to the processed data\n",
    "processed_path = \"../data/processed/\"\n",
    "\n",
    "# Load the processed datasets\n",
    "big_matrix = pd.read_csv(os.path.join(processed_path, \"big_matrix_processed.csv\"))\n",
    "small_matrix = pd.read_csv(os.path.join(processed_path, \"small_matrix_processed.csv\"))\n",
    "user_features = pd.read_csv(os.path.join(processed_path, \"user_features_processed.csv\"))\n",
    "item_daily_features = pd.read_csv(os.path.join(processed_path, \"item_daily_features_processed.csv\"))\n",
    "\n",
    "# Ensure datetime columns are in the correct format\n",
    "big_matrix = ensure_datetime(big_matrix, 'datetime')\n",
    "small_matrix = ensure_datetime(small_matrix, 'datetime')"
   ],
   "id": "3c83c64782717a81",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### User Features",
   "id": "5821bb09f7a1abd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:24:07.318132Z",
     "start_time": "2025-05-16T08:24:07.311712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_user_based_features(interactions, user_features):\n",
    "    # Total Videos Watched\n",
    "    total_videos_watched = interactions.groupby('user_id')['video_id'].count().reset_index(name='total_videos_watched')\n",
    "\n",
    "    # Average Watch Ratio\n",
    "    avg_watch_ratio = interactions.groupby('user_id')['watch_ratio'].mean().reset_index(name='avg_watch_ratio')\n",
    "\n",
    "    # Preferred Video Category\n",
    "    video_category_counts = item_daily_features.groupby('video_id')['feat'].first().reset_index()\n",
    "    interactions_with_categories = interactions.merge(video_category_counts, on='video_id', how='left')\n",
    "    preferred_categories = interactions_with_categories.groupby('user_id')['feat'].apply(lambda x: x.value_counts().idxmax() if not x.value_counts().empty else np.nan).reset_index(name='preferred_category')\n",
    "\n",
    "    # Merge with user_features\n",
    "    user_features = user_features.merge(total_videos_watched, on='user_id', how='left')\n",
    "    user_features = user_features.merge(avg_watch_ratio, on='user_id', how='left')\n",
    "    user_features = user_features.merge(preferred_categories, on='user_id', how='left')\n",
    "\n",
    "    return user_features"
   ],
   "id": "88d42a5ff3616c54",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Video Features",
   "id": "891c0f64d9315d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:24:07.340446Z",
     "start_time": "2025-05-16T08:24:07.335479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_video_based_features(item_daily_features):\n",
    "    # Total Likes\n",
    "    total_likes = item_daily_features.groupby('video_id')['like_cnt'].sum().reset_index(name='total_likes')\n",
    "\n",
    "    # Average Play Duration\n",
    "    avg_play_duration = item_daily_features.groupby('video_id')['play_duration'].mean().reset_index(name='avg_play_duration')\n",
    "\n",
    "    # Video Tags\n",
    "    video_tags = item_daily_features[['video_id', 'feat']].drop_duplicates()\n",
    "\n",
    "    # Merge with item_daily_features\n",
    "    item_daily_features.drop(columns=['feat'], inplace=True)\n",
    "\n",
    "    item_daily_features = item_daily_features.merge(total_likes, on='video_id', how='left')\n",
    "    item_daily_features = item_daily_features.merge(avg_play_duration, on='video_id', how='left')\n",
    "    item_daily_features = item_daily_features.merge(video_tags, on='video_id', how='left')\n",
    "\n",
    "    return item_daily_features"
   ],
   "id": "21a9c1a90bf05dfd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Interaction Features",
   "id": "a02ba7c03f42c867"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:24:07.374561Z",
     "start_time": "2025-05-16T08:24:07.370504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_interaction_based_features(interactions):\n",
    "    # User-Video Watch Count\n",
    "    user_video_watch_count = interactions.groupby(['user_id', 'video_id']).size().reset_index(name='user_video_watch_count')\n",
    "\n",
    "    # User-Video Average Watch Ratio\n",
    "    user_video_avg_watch_ratio = interactions.groupby(['user_id', 'video_id'])['watch_ratio'].mean().reset_index(name='user_video_avg_watch_ratio')\n",
    "\n",
    "    # Merge with interactions\n",
    "    interactions = interactions.merge(user_video_watch_count, on=['user_id', 'video_id'], how='left')\n",
    "    interactions = interactions.merge(user_video_avg_watch_ratio, on=['user_id', 'video_id'], how='left')\n",
    "\n",
    "    # Drop duplicates\n",
    "    interactions = interactions.drop_duplicates(subset=['user_id', 'video_id'])\n",
    "\n",
    "    return interactions"
   ],
   "id": "1fb53138e8fda938",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Social Features",
   "id": "3f88d10bf8d82c7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:24:07.396617Z",
     "start_time": "2025-05-16T08:24:07.391690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_social_based_features(user_features, interactions, item_daily_features):\n",
    "    # Number of Friends\n",
    "    num_friends = user_features[['user_id', 'friend_list']].copy()\n",
    "    num_friends['num_friends'] = num_friends['friend_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "    # Friends' Preferences\n",
    "    video_category_counts = item_daily_features.groupby('video_id')['feat'].first().reset_index()\n",
    "    interactions_with_categories = interactions.merge(video_category_counts, on='video_id', how='left')\n",
    "    friends_preferences = interactions_with_categories.groupby('user_id')['feat'].apply(lambda x: x.value_counts().idxmax() if not x.value_counts().empty else np.nan).reset_index(name='friends_preferred_category')\n",
    "\n",
    "    # Merge with user_features\n",
    "    user_features = user_features.merge(num_friends[['user_id', 'num_friends']], on='user_id', how='left')\n",
    "    user_features = user_features.merge(friends_preferences, on='user_id', how='left')\n",
    "\n",
    "    return user_features"
   ],
   "id": "3e576d39d051e3d2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Computing features",
   "id": "3b453311338f02ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:24:44.236754Z",
     "start_time": "2025-05-16T08:24:07.415912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create features for big_matrix and small_matrix\n",
    "interactions = pd.concat([big_matrix, small_matrix])\n",
    "\n",
    "print(\"Creating interaction-based features...\")\n",
    "interactions = create_interaction_based_features(interactions)\n",
    "\n",
    "# Create user-based features\n",
    "print(\"Creating user-based features...\")\n",
    "user_features = create_user_based_features(interactions, user_features)\n",
    "\n",
    "# Create video-based features\n",
    "print(\"Creating video-based features...\")\n",
    "item_daily_features = create_video_based_features(item_daily_features)\n",
    "\n",
    "# Create social-based features\n",
    "print(\"Creating social-based features...\")\n",
    "user_features = create_social_based_features(user_features, interactions, item_daily_features)\n",
    "\n",
    "# Split interactions into training and testing sets\n",
    "train_interactions, test_interactions = train_test_split(interactions, test_size=0.2, random_state=42)"
   ],
   "id": "301df995f64bd4c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interaction-based features...\n",
      "Creating user-based features...\n",
      "Creating video-based features...\n",
      "Creating social-based features...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save the engineered features",
   "id": "5397ffb3b3c7708d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:26:08.104257Z",
     "start_time": "2025-05-16T08:24:44.266644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the engineered features\n",
    "train_interactions.to_csv(os.path.join(processed_path, \"interactions_train.csv\"), index=False)\n",
    "test_interactions.to_csv(os.path.join(processed_path, \"interactions_test.csv\"), index=False)\n",
    "user_features.to_csv(os.path.join(processed_path, \"user_features.csv\"), index=False)\n",
    "item_daily_features.to_csv(os.path.join(processed_path, \"video_metadata.csv\"), index=False)\n",
    "\n",
    "# Create a sample submission file\n",
    "sample_submission = test_interactions[['user_id', 'video_id']].copy()\n",
    "sample_submission['prediction'] = 0  # Placeholder for predictions\n",
    "sample_submission.to_csv(os.path.join(processed_path, \"sample_submission.csv\"), index=False)\n",
    "\n",
    "print(\"Feature engineering completed successfully!\")\n"
   ],
   "id": "fe9175e2dc9d6df7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed successfully!\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
